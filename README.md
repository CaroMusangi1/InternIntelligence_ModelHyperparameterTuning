```
# ğŸ§  HYPERPARAMETER TUNING â€” RANDOM FOREST ON IRIS DATASET

## PROJECT OVERVIEW ğŸ“Œ
This project demonstrates how to improve model performance through hyperparameter tuning.  
Using the classic **Iris dataset**, we apply `GridSearchCV` to a **Random Forest Classifier** to find the best parameter combination.

---

## KEY CONCEPTS ğŸ”‘

ğŸ›ï¸ Hyperparameter Tuning â€” Adjusting settings like `n_estimators`, `max_depth`  
ğŸ§® Grid Search â€” Testing all possible combinations of parameters  
ğŸ”„ Cross-Validation â€” Evaluating model performance across multiple folds

---

## WORKFLOW STEPS âš™ï¸

### ğŸŒ± LOAD AND PREPROCESS DATA
- Load Iris dataset from `sklearn.datasets`
- Extract features (`X`) and target (`y`)

### âœ‚ï¸ SPLIT THE DATASET
- Use `train_test_split()` to split into training and test sets (80/20)

### ğŸ”§ DEFINE HYPERPARAMETER GRID
```python
param_grid = {
  'n_estimators': [50, 100, 150],
  'max_depth': [3, 5, 10],
  'min_samples_split': [2, 5, 10]
}
```

### ğŸ§  TUNE WITH GRIDSEARCHCV
- Use `GridSearchCV` with `RandomForestClassifier`  
- Automatically selects the best parameter combination

### ğŸ† EVALUATE THE BEST MODEL
- Print the best parameters  
- Test accuracy on the test set  
- Optional: visualize feature importance or confusion matrix

---

## LIBRARIES USED ğŸ§ª

- **scikit-learn** â€” Modeling, tuning, evaluation  
- **numpy** â€” Numerical operations  
- **matplotlib** â€” Visualizations (optional)  
- **pandas** â€” Data manipulation (optional)

---

## HOW TO USE THIS PROJECT ğŸš€

1. Open the notebook in **Google Colab**  
2. Run all cells step-by-step  
3. Modify the `param_grid` to test different parameters  
4. (Optional) Save the model using `joblib`

---

## OUTPUT ğŸ“¦

âœ… Best hyperparameters for the model  
âœ… Accuracy and evaluation metrics on test set  
âœ… (Optional) Feature importance or confusion matrix

---
